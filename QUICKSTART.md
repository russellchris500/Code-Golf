# Quick Start Guide

Get the AI Voice Assistant system up and running in minutes.

## What We Built

A **voice-enabled AI assistant system** with:
- ğŸ“± **Android app**: Voice/text input, shows transcript, plays audio responses
- ğŸ–¥ï¸ **Desktop app (Python)**: AI brain with STT, LLM processing (OpenAI/Claude), TTS
- â˜ï¸ **Backend (Go)**: Minimal relay server for routing between phone and desktop
- ğŸ—„ï¸ **PostgreSQL**: User accounts and conversation storage

## System Flow

```
ğŸ“± User speaks into phone
    â†“
â˜ï¸ Backend relays audio to user's desktop
    â†“
ğŸ–¥ï¸ Desktop: Whisper STT â†’ GPT/Claude â†’ OpenAI TTS
    â†“
â˜ï¸ Backend relays response back
    â†“
ğŸ“± Phone displays transcript and plays audio
```

## Prerequisites Checklist

- [ ] Windows computer for desktop app
- [ ] Android phone
- [ ] OpenAI API key (https://platform.openai.com/api-keys)
- [ ] Railway or Render account (free tier works)
- [ ] 30 minutes for setup

## Fast Setup (3 Steps)

### Step 1: Install Required Software

**On Windows:**

1. **Install Go**: https://go.dev/dl/ â†’ Download and run installer
2. **Install Python**: https://python.org â†’ Download 3.10+ and run installer
3. **Install protoc**:
   - Download from https://github.com/protocolbuffers/protobuf/releases
   - Extract to `C:\protoc`
   - Add `C:\protoc\bin` to PATH

4. Verify installations:
   ```bash
   go version
   python --version
   protoc --version
   ```

### Step 2: Set Up Backend (Choose one)

#### Option A: Local with Docker (Fastest)

```bash
cd C:\Users\csr\Code\Agent\docker
docker-compose up -d
```

Backend runs at `localhost:50051`

#### Option B: Deploy to Railway (Production)

```bash
# Install Railway CLI
npm install -g @railway/cli

# Login and deploy
cd C:\Users\csr\Code\Agent\backend
railway login
railway init
railway add --plugin postgresql
railway up

# Get your URL
railway open
```

### Step 3: Set Up Desktop App

```bash
cd C:\Users\csr\Code\Agent\desktop

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure
copy .env.example .env
notepad .env
```

Edit `.env`:
```
BACKEND_URL=localhost:50051  # or your Railway URL
USER_ID=test-user-123
OPENAI_API_KEY=sk-your-key-here
AI_PROVIDER=openai
```

Run:
```bash
python main.py
```

## Current Status

âœ… **Completed:**
- Project structure and monorepo
- Protocol Buffer definitions for gRPC
- Go backend with relay service
- Basic authentication (OAuth to be enhanced)
- Python desktop app with AI integration
- OpenAI Whisper STT
- OpenAI/Claude LLM support
- OpenAI TTS
- Docker setup
- Documentation

ğŸš§ **Next Steps:**
1. **Generate protobuf code**: Run `scripts\generate_proto.bat`
2. **Implement full OAuth**: Add Google OAuth token verification
3. **Build Android app**: Complete mobile application in Kotlin
4. **Test end-to-end**: Phone â†’ Desktop â†’ Phone flow
5. **Add conversation storage**: Save history to PostgreSQL
6. **Encrypt API keys**: Secure user API keys in database

## File Structure

```
Agent/
â”œâ”€â”€ README.md           â† Project overview
â”œâ”€â”€ SETUP.md           â† Detailed setup guide
â”œâ”€â”€ QUICKSTART.md      â† This file
â”œâ”€â”€ proto/             â† gRPC definitions
â”‚   â”œâ”€â”€ auth.proto
â”‚   â””â”€â”€ streaming.proto
â”œâ”€â”€ backend/           â† Go relay server
â”‚   â”œâ”€â”€ cmd/server/
â”‚   â”œâ”€â”€ internal/
â”‚   â””â”€â”€ pb/           â† Generated protobuf code (after running script)
â”œâ”€â”€ desktop/          â† Python AI app
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ ai/      â† STT, LLM, TTS
â”‚   â”‚   â”œâ”€â”€ grpc_client/
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ android/          â† Kotlin mobile app (to be built)
â”œâ”€â”€ docker/           â† Docker setup
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ Dockerfile.backend
â””â”€â”€ scripts/          â† Build scripts
    â””â”€â”€ generate_proto.bat
```

## Testing Without Android App

You can test the desktop AI components independently:

```python
# In Python console
from src.ai.stt import create_stt_provider
from src.ai.llm import create_llm_provider
from src.ai.tts import create_tts_provider

# Test STT (with audio file)
stt = create_stt_provider("openai", "your-api-key")
# transcript = stt.transcribe(audio_bytes)

# Test LLM
llm = create_llm_provider("openai", "your-api-key")
from src.ai.llm import Message
response = llm.generate_response([Message("user", "Hello!")])
print(response)

# Test TTS
tts = create_tts_provider("openai", "your-api-key")
audio = tts.synthesize("Hello, this is a test.")
# Play or save audio
```

## Immediate Next Actions

**To get the system working:**

1. **Generate protobuf code**:
   ```bash
   cd C:\Users\csr\Code\Agent
   scripts\generate_proto.bat
   ```

2. **Install Go dependencies**:
   ```bash
   cd backend
   go mod download
   ```

3. **Start backend** (if using Docker):
   ```bash
   cd docker
   docker-compose up
   ```

4. **Start desktop app**:
   ```bash
   cd desktop
   venv\Scripts\activate
   python main.py
   ```

5. **Build Android app** (see android/README.md)

## Getting Help

- **Backend issues**: Check [backend/README.md](backend/README.md)
- **Desktop issues**: Check [desktop/README.md](desktop/README.md)
- **Android issues**: Check [android/README.md](android/README.md)
- **Full setup**: See [SETUP.md](SETUP.md)

## Architecture Decisions

**Why this architecture?**
- **Desktop does AI processing**: More powerful hardware, easier to switch AI providers, keeps user API keys local
- **Backend is minimal relay**: Scalable, simple, just routes packets
- **1:1 pairing**: Each user has their own desktop and phone, auto-paired by user ID
- **Pluggable AI**: Easy to switch between OpenAI, Claude, or local models

**Scaling path:**
- Phase 1 (MVP): Single backend server, ~100 users
- Phase 2: Multiple backend servers + Redis pub/sub
- Phase 3: Microservices architecture with message brokers

## Cost Estimates

**Development/Testing (per month):**
- Railway/Render backend: $0 (free tier)
- OpenAI API: $5-20 (depending on usage)
- **Total**: ~$5-20/month

**Production (per 1000 users):**
- Backend hosting: $20-50
- Database: $15-30
- OpenAI API (user-paid): $0 for you
- **Total**: ~$35-80/month

## What Makes This Project Scalable

1. **Stateless backend**: Can add more servers easily
2. **gRPC**: Efficient binary protocol
3. **User-provided API keys**: No centralized AI costs
4. **Minimal relay**: Backend doesn't process AI, just routes
5. **Protocol Buffers**: Versioned API contracts
6. **Docker**: Easy deployment and scaling

Enjoy building your AI voice assistant! ğŸš€
